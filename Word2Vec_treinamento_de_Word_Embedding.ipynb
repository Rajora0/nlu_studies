{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajora0/nlp_studies/blob/main/Word2Vec_treinamento_de_Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZWS2FBJcz6W"
      },
      "source": [
        "# Word2Vec: treinamento de Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XatJ07AUdHkt"
      },
      "source": [
        "## Montar Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbVRYw_FcN8p",
        "outputId": "658b47cf-6e3b-400f-9f5e-dd92c6ec38f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive/; to attempt to forcibly remount, call drive.mount(\"/gdrive/\", force_remount=True).\n",
            "cbow_s300.txt  skip_s300.txt  teste.csv  treino.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "\n",
        "!ls '/gdrive/MyDrive/NLP_ESTUDOS/Dados/word2vec'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MLeQTLsxtue"
      },
      "source": [
        "## Carregando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EegtW3yxxsG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA3Lm6-Nx9-g"
      },
      "outputs": [],
      "source": [
        "path = '/gdrive/MyDrive/NLP_ESTUDOS/Dados/word2vec/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woumVYVox6ja"
      },
      "outputs": [],
      "source": [
        "dados_treino = pd.read_csv(path+\"treino.csv\")\n",
        "dados_teste = pd.read_csv(path+\"teste.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laau2ebZcO4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "131de783-20b6-40a2-a1b6-8c4b4b146964"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
              "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
              "2  Apesar de larga vitória nas legislativas, Macr...   \n",
              "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
              "4  Após queda em maio, a atividade econômica sobe...   \n",
              "\n",
              "                                                text        date   category  \\\n",
              "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
              "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
              "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
              "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
              "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
              "\n",
              "  subcategory                                               link  \n",
              "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
              "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
              "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
              "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
              "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e63ca59d-7d6e-4c00-8faa-e46b672bd635\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
              "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
              "      <td>2017-04-28</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
              "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
              "      <td>2017-04-23</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
              "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
              "      <td>2017-06-19</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
              "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
              "      <td>2015-07-24</td>\n",
              "      <td>cotidiano</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
              "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
              "      <td>2017-08-17</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e63ca59d-7d6e-4c00-8faa-e46b672bd635')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e63ca59d-7d6e-4c00-8faa-e46b672bd635 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e63ca59d-7d6e-4c00-8faa-e46b672bd635');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dados_treino.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdXo-gULcQ6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "c8a261cf-e1f7-4740-ce53-ceaf0ec84838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0                                     Grandes irmãos   \n",
              "1  Haddad congela orçamento e suspende emendas de...   \n",
              "2  Proposta de reforma da Fifa tem a divulgação d...   \n",
              "3  Mercado incipiente, internet das coisas conect...   \n",
              "4  Mortes: Psicanalista, estudou o autismo em cri...   \n",
              "\n",
              "                                                text        date   category  \\\n",
              "0  RIO DE JANEIRO - O Brasil, cada vez menos famí...  2017-03-06    colunas   \n",
              "1  O prefeito de São Paulo, Fernando Haddad (PT),...  2016-08-10    colunas   \n",
              "2  A Fifa divulgou, nesta quinta (10), um relatór...  2015-10-09    esporte   \n",
              "3  Bueiros, coleiras, aparelhos hospitalares, ele...  2016-11-09    mercado   \n",
              "4  Toda vez que o grupo de amigos de Silvana Rabe...  2017-02-07  cotidiano   \n",
              "\n",
              "     subcategory                                               link  \n",
              "0      ruycastro  http://www1.folha.uol.com.br/colunas/ruycastro...  \n",
              "1  monicabergamo  http://www1.folha.uol.com.br/colunas/monicaber...  \n",
              "2            NaN  http://www1.folha.uol.com.br/esporte/2015/09/1...  \n",
              "3            NaN  http://www1.folha.uol.com.br/mercado/2016/09/1...  \n",
              "4            NaN  http://www1.folha.uol.com.br/cotidiano/2017/07...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a1ab5e7-2a2c-4652-b11b-8558b722a2df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grandes irmãos</td>\n",
              "      <td>RIO DE JANEIRO - O Brasil, cada vez menos famí...</td>\n",
              "      <td>2017-03-06</td>\n",
              "      <td>colunas</td>\n",
              "      <td>ruycastro</td>\n",
              "      <td>http://www1.folha.uol.com.br/colunas/ruycastro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Haddad congela orçamento e suspende emendas de...</td>\n",
              "      <td>O prefeito de São Paulo, Fernando Haddad (PT),...</td>\n",
              "      <td>2016-08-10</td>\n",
              "      <td>colunas</td>\n",
              "      <td>monicabergamo</td>\n",
              "      <td>http://www1.folha.uol.com.br/colunas/monicaber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Proposta de reforma da Fifa tem a divulgação d...</td>\n",
              "      <td>A Fifa divulgou, nesta quinta (10), um relatór...</td>\n",
              "      <td>2015-10-09</td>\n",
              "      <td>esporte</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/esporte/2015/09/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mercado incipiente, internet das coisas conect...</td>\n",
              "      <td>Bueiros, coleiras, aparelhos hospitalares, ele...</td>\n",
              "      <td>2016-11-09</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2016/09/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mortes: Psicanalista, estudou o autismo em cri...</td>\n",
              "      <td>Toda vez que o grupo de amigos de Silvana Rabe...</td>\n",
              "      <td>2017-02-07</td>\n",
              "      <td>cotidiano</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/cotidiano/2017/07...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a1ab5e7-2a2c-4652-b11b-8558b722a2df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a1ab5e7-2a2c-4652-b11b-8558b722a2df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a1ab5e7-2a2c-4652-b11b-8558b722a2df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dados_teste.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "pNT8n4EBER_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://spacy.io/"
      ],
      "metadata": {
        "id": "5oJzRNUPINHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install spacy -qq\n",
        "#!python -m spacy download pt_core_news_sm -qq"
      ],
      "metadata": {
        "id": "srfm1BxqEU_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "nlp"
      ],
      "metadata": {
        "id": "fQcKGGTnFMDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9ab2c4-3840-406a-8a0b-41ec6c000ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.pt.Portuguese at 0x7f6622c12dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Rio de Janeiro é uma cidade maravilhosa\"\n",
        "doc = nlp(texto)"
      ],
      "metadata": {
        "id": "2aKXGKKgMqbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36i7_8AAMyYB",
        "outputId": "008edbbd-7ef1-4cde-d7aa-0e581f7184f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZBlCVu7MzZK",
        "outputId": "6a524c03-b543-418f-b90c-59235a64922d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rio"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc.ents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY4FIOonNi_7",
        "outputId": "b97690bf-9f7b-4275-9433-9e1616951052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Rio de Janeiro,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaYP8bAzNtts",
        "outputId": "ae782c2b-44bc-402d-a36c-ed7e8eafb17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[1].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jgW612_N3jh",
        "outputId": "a4ba7a64-b789-44dc-8439-e360591f57bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tratando nossos dados"
      ],
      "metadata": {
        "id": "HgPzcnVsRCAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time"
      ],
      "metadata": {
        "id": "nmEMueCiTEF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"])\n"
      ],
      "metadata": {
        "id": "tI79Qr1rREbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trata_textos(doc):\n",
        "    tokens_validos = []\n",
        "    for token in doc:\n",
        "        e_valido = not token.is_stop and token.is_alpha\n",
        "        if e_valido:\n",
        "            tokens_validos.append(token.text)\n",
        "\n",
        "    if len(tokens_validos) > 2:\n",
        "        return  \" \".join(tokens_validos)\n",
        "\n",
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "doc = nlp(texto)\n",
        "trata_textos(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hx_8pcIfSyRA",
        "outputId": "d4b55ed1-afaa-4e68-ca73-f40468a53f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rio Janeiro cidade maravilhosa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "doc = nlp(texto)\n",
        "trata_textos(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IVw9EuGKS3Lg",
        "outputId": "85bbd572-fb2c-4116-f435-862d8aea9e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rio Janeiro cidade maravilhosa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time()\n",
        "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
        "                                                        batch_size = 1000,\n",
        "                                                        n_process = -1)]\n",
        "\n",
        "tf = time() - t0\n",
        "\n",
        "print(tf/60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ksTtCLS7hm",
        "outputId": "523cfcca-ea22-4e14-bb0b-ec26ba23a5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.615842342376709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
        "titulos_tratados.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qU7nySgkTCM4",
        "outputId": "cdbbef2b-c506-49ba-a395-bfc5417b13fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titulo\n",
              "0  polêmica marine le pen abomina negacionistas h...\n",
              "1  macron e le pen a o turno frança revés siglas ...\n",
              "2  apesar larga vitória legislativas macron terá ...\n",
              "3  governo antecipa balanço e alckmin anuncia que...\n",
              "4     queda maio a atividade econômica sobe junho bc"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-773f6d44-51dd-438f-8dad-6c4888b7d5b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>macron e le pen a o turno frança revés siglas ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>governo antecipa balanço e alckmin anuncia que...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>queda maio a atividade econômica sobe junho bc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-773f6d44-51dd-438f-8dad-6c4888b7d5b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-773f6d44-51dd-438f-8dad-6c4888b7d5b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-773f6d44-51dd-438f-8dad-6c4888b7d5b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construindo o Word2Vec"
      ],
      "metadata": {
        "id": "p-ZPf6D_kDrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "WxNYDI2mnvpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(titulos_tratados))\n",
        "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
        "print(len(titulos_tratados))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPhq6jBqkQ0T",
        "outputId": "d16b524e-af26-4abd-a046-2f71a711f5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90000\n",
            "86113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
      ],
      "metadata": {
        "id": "RvRvFxV1noU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf-jcDkcnqw4",
        "outputId": "236ef549-503c-4c08-d707-0dc4c3a76fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-12 12:00:45,402 : - collecting all words and their counts\n",
            "2022-05-12 12:00:45,404 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-12 12:00:45,426 : - PROGRESS: at sentence #5000, processed 34716 words, keeping 10129 word types\n",
            "2022-05-12 12:00:45,443 : - PROGRESS: at sentence #10000, processed 69298 words, keeping 14909 word types\n",
            "2022-05-12 12:00:45,458 : - PROGRESS: at sentence #15000, processed 103841 words, keeping 18223 word types\n",
            "2022-05-12 12:00:45,475 : - PROGRESS: at sentence #20000, processed 138620 words, keeping 20969 word types\n",
            "2022-05-12 12:00:45,492 : - PROGRESS: at sentence #25000, processed 173257 words, keeping 23410 word types\n",
            "2022-05-12 12:00:45,516 : - PROGRESS: at sentence #30000, processed 207976 words, keeping 25453 word types\n",
            "2022-05-12 12:00:45,537 : - PROGRESS: at sentence #35000, processed 242567 words, keeping 27263 word types\n",
            "2022-05-12 12:00:45,554 : - PROGRESS: at sentence #40000, processed 277254 words, keeping 28992 word types\n",
            "2022-05-12 12:00:45,570 : - PROGRESS: at sentence #45000, processed 311910 words, keeping 30561 word types\n",
            "2022-05-12 12:00:45,586 : - PROGRESS: at sentence #50000, processed 346641 words, keeping 31924 word types\n",
            "2022-05-12 12:00:45,602 : - PROGRESS: at sentence #55000, processed 381564 words, keeping 33224 word types\n",
            "2022-05-12 12:00:45,620 : - PROGRESS: at sentence #60000, processed 416318 words, keeping 34458 word types\n",
            "2022-05-12 12:00:45,638 : - PROGRESS: at sentence #65000, processed 451172 words, keeping 35585 word types\n",
            "2022-05-12 12:00:45,654 : - PROGRESS: at sentence #70000, processed 485882 words, keeping 36651 word types\n",
            "2022-05-12 12:00:45,672 : - PROGRESS: at sentence #75000, processed 520667 words, keeping 37767 word types\n",
            "2022-05-12 12:00:45,688 : - PROGRESS: at sentence #80000, processed 555521 words, keeping 38741 word types\n",
            "2022-05-12 12:00:45,704 : - PROGRESS: at sentence #85000, processed 590198 words, keeping 39739 word types\n",
            "2022-05-12 12:00:45,710 : - collected 39968 word types from a corpus of 597929 raw words and 86113 sentences\n",
            "2022-05-12 12:00:45,712 : - Loading a fresh vocabulary\n",
            "2022-05-12 12:00:45,773 : - effective_min_count=5 retains 13006 unique words (32% of original 39968, drops 26962)\n",
            "2022-05-12 12:00:45,775 : - effective_min_count=5 leaves 552614 word corpus (92% of original 597929, drops 45315)\n",
            "2022-05-12 12:00:45,823 : - deleting the raw counts dictionary of 39968 items\n",
            "2022-05-12 12:00:45,826 : - sample=0.001 downsamples 11 most-common words\n",
            "2022-05-12 12:00:45,830 : - downsampling leaves estimated 502900 word corpus (91.0% of prior 552614)\n",
            "2022-05-12 12:00:45,886 : - estimated required memory for 13006 words and 300 dimensions: 37717400 bytes\n",
            "2022-05-12 12:00:45,888 : - resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinando o Word2Vec"
      ],
      "metadata": {
        "id": "3D-cBS_vHCG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(w2v_modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvRtb8ABG8h7",
        "outputId": "602a6483-3eb8-420a-a79d-966544d1c529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_adapt_by_suffix',\n",
              " '_check_input_data_sanity',\n",
              " '_check_training_sanity',\n",
              " '_clear_post_train',\n",
              " '_do_train_epoch',\n",
              " '_do_train_job',\n",
              " '_get_job_params',\n",
              " '_get_thread_working_mem',\n",
              " '_job_producer',\n",
              " '_load_specials',\n",
              " '_log_epoch_end',\n",
              " '_log_epoch_progress',\n",
              " '_log_progress',\n",
              " '_log_train_end',\n",
              " '_minimize_model',\n",
              " '_raw_word_count',\n",
              " '_save_specials',\n",
              " '_set_train_params',\n",
              " '_smart_save',\n",
              " '_train_epoch',\n",
              " '_train_epoch_corpusfile',\n",
              " '_update_job_params',\n",
              " '_worker_loop',\n",
              " '_worker_loop_corpusfile',\n",
              " 'accuracy',\n",
              " 'alpha',\n",
              " 'batch_words',\n",
              " 'build_vocab',\n",
              " 'build_vocab_from_freq',\n",
              " 'callbacks',\n",
              " 'cbow_mean',\n",
              " 'clear_sims',\n",
              " 'compute_loss',\n",
              " 'corpus_count',\n",
              " 'corpus_total_words',\n",
              " 'cum_table',\n",
              " 'delete_temporary_training_data',\n",
              " 'doesnt_match',\n",
              " 'epochs',\n",
              " 'estimate_memory',\n",
              " 'evaluate_word_pairs',\n",
              " 'get_latest_training_loss',\n",
              " 'hashfxn',\n",
              " 'hs',\n",
              " 'init_sims',\n",
              " 'intersect_word2vec_format',\n",
              " 'iter',\n",
              " 'layer1_size',\n",
              " 'load',\n",
              " 'load_word2vec_format',\n",
              " 'log_accuracy',\n",
              " 'max_final_vocab',\n",
              " 'min_alpha',\n",
              " 'min_alpha_yet_reached',\n",
              " 'min_count',\n",
              " 'model_trimmed_post_training',\n",
              " 'most_similar',\n",
              " 'most_similar_cosmul',\n",
              " 'n_similarity',\n",
              " 'negative',\n",
              " 'ns_exponent',\n",
              " 'predict_output_word',\n",
              " 'random',\n",
              " 'reset_from',\n",
              " 'running_training_loss',\n",
              " 'sample',\n",
              " 'save',\n",
              " 'save_word2vec_format',\n",
              " 'score',\n",
              " 'sg',\n",
              " 'similar_by_vector',\n",
              " 'similar_by_word',\n",
              " 'similarity',\n",
              " 'syn0_lockf',\n",
              " 'syn1',\n",
              " 'syn1neg',\n",
              " 'total_train_time',\n",
              " 'train',\n",
              " 'train_count',\n",
              " 'trainables',\n",
              " 'vector_size',\n",
              " 'vocabulary',\n",
              " 'window',\n",
              " 'wmdistance',\n",
              " 'workers',\n",
              " 'wv']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJlB4JZ2G_t9",
        "outputId": "38021394-bfc9-4ca2-eeb7-4e616428ff72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86113"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.train(lista_lista_tokens, \n",
        "                 total_examples=w2v_modelo.corpus_count,\n",
        "                 epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q_i2i0uHBQt",
        "outputId": "2e57500f-2c9e-4645-b9f6-897b940c5f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-12 12:00:48,672 : - training model with 3 workers on 13006 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
            "2022-05-12 12:00:49,697 : - EPOCH 1 - PROGRESS: at 65.27% examples, 324909 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:00:50,149 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:50,151 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:50,176 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:50,178 : - EPOCH - 1 : training on 597929 raw words (502873 effective words) took 1.5s, 337572 effective words/s\n",
            "2022-05-12 12:00:51,235 : - EPOCH 2 - PROGRESS: at 68.60% examples, 330871 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:00:51,623 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:51,631 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:51,641 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:51,642 : - EPOCH - 2 : training on 597929 raw words (502956 effective words) took 1.4s, 347047 effective words/s\n",
            "2022-05-12 12:00:52,690 : - EPOCH 3 - PROGRESS: at 68.59% examples, 335775 words/s, in_qsize 6, out_qsize 1\n",
            "2022-05-12 12:00:53,092 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:53,096 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:53,105 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:53,107 : - EPOCH - 3 : training on 597929 raw words (502776 effective words) took 1.4s, 348525 effective words/s\n",
            "2022-05-12 12:00:54,144 : - EPOCH 4 - PROGRESS: at 66.92% examples, 328820 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:00:54,526 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:54,556 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:54,566 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:54,568 : - EPOCH - 4 : training on 597929 raw words (502869 effective words) took 1.4s, 347616 effective words/s\n",
            "2022-05-12 12:00:55,596 : - EPOCH 5 - PROGRESS: at 70.26% examples, 347343 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:00:55,961 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:55,970 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:55,989 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:55,991 : - EPOCH - 5 : training on 597929 raw words (502809 effective words) took 1.4s, 356420 effective words/s\n",
            "2022-05-12 12:00:57,070 : - EPOCH 6 - PROGRESS: at 70.26% examples, 334704 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:00:57,405 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:57,431 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:57,436 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:57,437 : - EPOCH - 6 : training on 597929 raw words (502964 effective words) took 1.4s, 353573 effective words/s\n",
            "2022-05-12 12:00:58,461 : - EPOCH 7 - PROGRESS: at 66.94% examples, 332751 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:00:58,840 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:00:58,868 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:00:58,876 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:00:58,878 : - EPOCH - 7 : training on 597929 raw words (502982 effective words) took 1.4s, 352209 effective words/s\n",
            "2022-05-12 12:00:59,896 : - EPOCH 8 - PROGRESS: at 68.60% examples, 341570 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:01:00,275 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:00,308 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:00,314 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:00,317 : - EPOCH - 8 : training on 597929 raw words (502740 effective words) took 1.4s, 351614 effective words/s\n",
            "2022-05-12 12:01:01,369 : - EPOCH 9 - PROGRESS: at 70.26% examples, 340645 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:01:01,697 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:01,727 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:01,741 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:01,742 : - EPOCH - 9 : training on 597929 raw words (502991 effective words) took 1.4s, 356697 effective words/s\n",
            "2022-05-12 12:01:02,766 : - EPOCH 10 - PROGRESS: at 68.60% examples, 342304 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:03,147 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:03,153 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:03,174 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:03,175 : - EPOCH - 10 : training on 597929 raw words (502956 effective words) took 1.4s, 355077 effective words/s\n",
            "2022-05-12 12:01:04,219 : - EPOCH 11 - PROGRESS: at 68.61% examples, 334174 words/s, in_qsize 5, out_qsize 2\n",
            "2022-05-12 12:01:04,599 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:04,610 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:04,622 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:04,623 : - EPOCH - 11 : training on 597929 raw words (502851 effective words) took 1.4s, 350337 effective words/s\n",
            "2022-05-12 12:01:05,675 : - EPOCH 12 - PROGRESS: at 71.91% examples, 353859 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:05,990 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:06,009 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:06,021 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:06,022 : - EPOCH - 12 : training on 597929 raw words (502756 effective words) took 1.4s, 367257 effective words/s\n",
            "2022-05-12 12:01:07,076 : - EPOCH 13 - PROGRESS: at 71.95% examples, 347579 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:07,413 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:07,429 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:07,440 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:07,441 : - EPOCH - 13 : training on 597929 raw words (503168 effective words) took 1.4s, 357902 effective words/s\n",
            "2022-05-12 12:01:08,478 : - EPOCH 14 - PROGRESS: at 70.26% examples, 345483 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:08,830 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:08,863 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:08,875 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:08,876 : - EPOCH - 14 : training on 597929 raw words (502775 effective words) took 1.4s, 354155 effective words/s\n",
            "2022-05-12 12:01:09,915 : - EPOCH 15 - PROGRESS: at 70.26% examples, 351935 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:10,271 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:10,289 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:10,293 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:10,295 : - EPOCH - 15 : training on 597929 raw words (502737 effective words) took 1.4s, 363631 effective words/s\n",
            "2022-05-12 12:01:11,324 : - EPOCH 16 - PROGRESS: at 70.26% examples, 348099 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:11,678 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:11,712 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:11,721 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:11,722 : - EPOCH - 16 : training on 597929 raw words (502907 effective words) took 1.4s, 356058 effective words/s\n",
            "2022-05-12 12:01:12,765 : - EPOCH 17 - PROGRESS: at 71.93% examples, 350081 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:13,082 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:13,104 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:13,111 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:13,112 : - EPOCH - 17 : training on 597929 raw words (502760 effective words) took 1.4s, 364448 effective words/s\n",
            "2022-05-12 12:01:14,144 : - EPOCH 18 - PROGRESS: at 70.26% examples, 347547 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:14,512 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:14,522 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:14,550 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:14,552 : - EPOCH - 18 : training on 597929 raw words (502874 effective words) took 1.4s, 353122 effective words/s\n",
            "2022-05-12 12:01:15,585 : - EPOCH 19 - PROGRESS: at 71.91% examples, 360339 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:15,923 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:15,954 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:15,964 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:15,965 : - EPOCH - 19 : training on 597929 raw words (502921 effective words) took 1.4s, 363592 effective words/s\n",
            "2022-05-12 12:01:16,981 : - EPOCH 20 - PROGRESS: at 65.26% examples, 326283 words/s, in_qsize 6, out_qsize 2\n",
            "2022-05-12 12:01:17,374 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:17,382 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:17,403 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:17,405 : - EPOCH - 20 : training on 597929 raw words (503017 effective words) took 1.4s, 351852 effective words/s\n",
            "2022-05-12 12:01:18,425 : - EPOCH 21 - PROGRESS: at 70.26% examples, 351179 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:18,813 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:18,819 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:18,847 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:18,849 : - EPOCH - 21 : training on 597929 raw words (502839 effective words) took 1.4s, 351873 effective words/s\n",
            "2022-05-12 12:01:19,883 : - EPOCH 22 - PROGRESS: at 70.26% examples, 352183 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:20,245 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:20,262 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:20,274 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:20,277 : - EPOCH - 22 : training on 597929 raw words (502962 effective words) took 1.4s, 360103 effective words/s\n",
            "2022-05-12 12:01:21,304 : - EPOCH 23 - PROGRESS: at 68.61% examples, 340611 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:21,659 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:21,691 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:21,696 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:21,698 : - EPOCH - 23 : training on 597929 raw words (503021 effective words) took 1.4s, 357809 effective words/s\n",
            "2022-05-12 12:01:22,736 : - EPOCH 24 - PROGRESS: at 71.95% examples, 352491 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:23,092 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:23,123 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:23,126 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:23,127 : - EPOCH - 24 : training on 597929 raw words (502603 effective words) took 1.4s, 354920 effective words/s\n",
            "2022-05-12 12:01:24,144 : - EPOCH 25 - PROGRESS: at 70.26% examples, 350827 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:24,504 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:24,513 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:24,525 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:24,526 : - EPOCH - 25 : training on 597929 raw words (502937 effective words) took 1.4s, 362105 effective words/s\n",
            "2022-05-12 12:01:25,577 : - EPOCH 26 - PROGRESS: at 71.95% examples, 348076 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:01:25,906 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:25,914 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:25,923 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:25,925 : - EPOCH - 26 : training on 597929 raw words (503056 effective words) took 1.4s, 362809 effective words/s\n",
            "2022-05-12 12:01:26,962 : - EPOCH 27 - PROGRESS: at 70.26% examples, 347686 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:27,302 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:27,326 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:27,337 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:27,338 : - EPOCH - 27 : training on 597929 raw words (502875 effective words) took 1.4s, 361468 effective words/s\n",
            "2022-05-12 12:01:28,365 : - EPOCH 28 - PROGRESS: at 71.91% examples, 358628 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:28,704 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:28,728 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:28,734 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:28,735 : - EPOCH - 28 : training on 597929 raw words (502962 effective words) took 1.4s, 365148 effective words/s\n",
            "2022-05-12 12:01:29,759 : - EPOCH 29 - PROGRESS: at 68.60% examples, 340951 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:30,135 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:30,146 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:30,164 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:30,165 : - EPOCH - 29 : training on 597929 raw words (503051 effective words) took 1.4s, 354698 effective words/s\n",
            "2022-05-12 12:01:31,191 : - EPOCH 30 - PROGRESS: at 70.29% examples, 348329 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:31,546 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:31,557 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:31,568 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:31,570 : - EPOCH - 30 : training on 597929 raw words (502852 effective words) took 1.4s, 361287 effective words/s\n",
            "2022-05-12 12:01:31,574 : - training on a 17937870 raw words (15086840 effective words) took 42.9s, 351677 effective words/s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15086840, 17937870)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"google\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4az8bDKPHwVw",
        "outputId": "bf8bef0f-7267-4f40-ae20-90243ab18c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-12 12:01:31,584 : - precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', 0.5999081134796143),\n",
              " ('facebook', 0.5410079956054688),\n",
              " ('amazon', 0.5001060962677002),\n",
              " ('waze', 0.4755364656448364),\n",
              " ('fbi', 0.47435659170150757),\n",
              " ('uber', 0.47419095039367676),\n",
              " ('airbnb', 0.4717792868614197),\n",
              " ('web', 0.4630432724952698),\n",
              " ('buffett', 0.44291895627975464),\n",
              " ('canais', 0.43591761589050293)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"microsoft\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "potM8ilaHyff",
        "outputId": "348404c1-8665-4f58-b112-5a62655a2dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unilever', 0.6132704019546509),\n",
              " ('sony', 0.5909816026687622),\n",
              " ('amazon', 0.5897475481033325),\n",
              " ('tesla', 0.588370680809021),\n",
              " ('canais', 0.5589038133621216),\n",
              " ('walmart', 0.5515804290771484),\n",
              " ('sky', 0.5429564714431763),\n",
              " ('lego', 0.5395606756210327),\n",
              " ('chrysler', 0.5393645763397217),\n",
              " ('street', 0.5308616757392883)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"barcelona\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCnUrkEzH0Im",
        "outputId": "9d28965d-c226-42c8-cf29-b418c15fea03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barça', 0.6314722299575806),\n",
              " ('chelsea', 0.6138635873794556),\n",
              " ('psg', 0.6048184633255005),\n",
              " ('bayern', 0.5881408452987671),\n",
              " ('leicester', 0.5868918895721436),\n",
              " ('juventus', 0.5865355134010315),\n",
              " ('munique', 0.5690410137176514),\n",
              " ('figueirense', 0.5634949207305908),\n",
              " ('madrid', 0.5630789995193481),\n",
              " ('united', 0.5603851079940796)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"messi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob4duhRWH12_",
        "outputId": "1de97f26-30e9-4866-c081-f50715e76e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('suárez', 0.6128507256507874),\n",
              " ('cristiano', 0.5684494972229004),\n",
              " ('cavani', 0.5360791683197021),\n",
              " ('neymar', 0.5292573571205139),\n",
              " ('benzema', 0.5154162049293518),\n",
              " ('tevez', 0.5143914222717285),\n",
              " ('barcelona', 0.510454535484314),\n",
              " ('barça', 0.5050179958343506),\n",
              " ('psg', 0.49441391229629517),\n",
              " ('chuteiras', 0.4937223196029663)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"gm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mau9Uua-H92A",
        "outputId": "d089d678-c244-4ed6-ead7-b293368a2941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chrysler', 0.6866105198860168),\n",
              " ('honda', 0.6504881381988525),\n",
              " ('fiat', 0.6390398144721985),\n",
              " ('toyota', 0.6367384195327759),\n",
              " ('volks', 0.6337071657180786),\n",
              " ('embraer', 0.6161869764328003),\n",
              " ('renault', 0.6044415235519409),\n",
              " ('tesla', 0.5988296270370483),\n",
              " ('sabmiller', 0.5901549458503723),\n",
              " ('inbev', 0.5830637812614441)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinamento do modelo Skip-Gram\n",
        "w2v_modelo_sg = Word2Vec(sg = 1,\n",
        "                      window = 5,\n",
        "                      size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
        "\n",
        "w2v_modelo_sg.train(lista_lista_tokens, \n",
        "                 total_examples=w2v_modelo_sg.corpus_count,\n",
        "                 epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTqs0zk-ICla",
        "outputId": "a2e73a91-8487-4dfd-a167-adea87e339de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-12 12:01:31,713 : - collecting all words and their counts\n",
            "2022-05-12 12:01:31,716 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-12 12:01:31,739 : - PROGRESS: at sentence #5000, processed 34716 words, keeping 10129 word types\n",
            "2022-05-12 12:01:31,765 : - PROGRESS: at sentence #10000, processed 69298 words, keeping 14909 word types\n",
            "2022-05-12 12:01:31,787 : - PROGRESS: at sentence #15000, processed 103841 words, keeping 18223 word types\n",
            "2022-05-12 12:01:31,808 : - PROGRESS: at sentence #20000, processed 138620 words, keeping 20969 word types\n",
            "2022-05-12 12:01:31,825 : - PROGRESS: at sentence #25000, processed 173257 words, keeping 23410 word types\n",
            "2022-05-12 12:01:31,839 : - PROGRESS: at sentence #30000, processed 207976 words, keeping 25453 word types\n",
            "2022-05-12 12:01:31,852 : - PROGRESS: at sentence #35000, processed 242567 words, keeping 27263 word types\n",
            "2022-05-12 12:01:31,868 : - PROGRESS: at sentence #40000, processed 277254 words, keeping 28992 word types\n",
            "2022-05-12 12:01:31,884 : - PROGRESS: at sentence #45000, processed 311910 words, keeping 30561 word types\n",
            "2022-05-12 12:01:31,898 : - PROGRESS: at sentence #50000, processed 346641 words, keeping 31924 word types\n",
            "2022-05-12 12:01:31,913 : - PROGRESS: at sentence #55000, processed 381564 words, keeping 33224 word types\n",
            "2022-05-12 12:01:31,929 : - PROGRESS: at sentence #60000, processed 416318 words, keeping 34458 word types\n",
            "2022-05-12 12:01:31,945 : - PROGRESS: at sentence #65000, processed 451172 words, keeping 35585 word types\n",
            "2022-05-12 12:01:31,959 : - PROGRESS: at sentence #70000, processed 485882 words, keeping 36651 word types\n",
            "2022-05-12 12:01:31,974 : - PROGRESS: at sentence #75000, processed 520667 words, keeping 37767 word types\n",
            "2022-05-12 12:01:31,994 : - PROGRESS: at sentence #80000, processed 555521 words, keeping 38741 word types\n",
            "2022-05-12 12:01:32,012 : - PROGRESS: at sentence #85000, processed 590198 words, keeping 39739 word types\n",
            "2022-05-12 12:01:32,019 : - collected 39968 word types from a corpus of 597929 raw words and 86113 sentences\n",
            "2022-05-12 12:01:32,021 : - Loading a fresh vocabulary\n",
            "2022-05-12 12:01:32,074 : - effective_min_count=5 retains 13006 unique words (32% of original 39968, drops 26962)\n",
            "2022-05-12 12:01:32,076 : - effective_min_count=5 leaves 552614 word corpus (92% of original 597929, drops 45315)\n",
            "2022-05-12 12:01:32,123 : - deleting the raw counts dictionary of 39968 items\n",
            "2022-05-12 12:01:32,126 : - sample=0.001 downsamples 11 most-common words\n",
            "2022-05-12 12:01:32,127 : - downsampling leaves estimated 502900 word corpus (91.0% of prior 552614)\n",
            "2022-05-12 12:01:32,189 : - estimated required memory for 13006 words and 300 dimensions: 37717400 bytes\n",
            "2022-05-12 12:01:32,191 : - resetting layer weights\n",
            "2022-05-12 12:01:34,933 : - training model with 3 workers on 13006 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
            "2022-05-12 12:01:35,990 : - EPOCH 1 - PROGRESS: at 16.78% examples, 80658 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:37,018 : - EPOCH 1 - PROGRESS: at 35.17% examples, 85259 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:38,030 : - EPOCH 1 - PROGRESS: at 63.60% examples, 103632 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:39,071 : - EPOCH 1 - PROGRESS: at 93.63% examples, 114148 words/s, in_qsize 4, out_qsize 0\n",
            "2022-05-12 12:01:39,188 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:39,213 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:39,239 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:39,242 : - EPOCH - 1 : training on 597929 raw words (502813 effective words) took 4.3s, 117087 effective words/s\n",
            "2022-05-12 12:01:40,334 : - EPOCH 2 - PROGRESS: at 26.80% examples, 125406 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:41,393 : - EPOCH 2 - PROGRESS: at 56.93% examples, 134140 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:42,441 : - EPOCH 2 - PROGRESS: at 86.96% examples, 137462 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:42,743 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:42,829 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:42,851 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:42,852 : - EPOCH - 2 : training on 597929 raw words (503016 effective words) took 3.6s, 140050 effective words/s\n",
            "2022-05-12 12:01:43,967 : - EPOCH 3 - PROGRESS: at 28.48% examples, 129876 words/s, in_qsize 6, out_qsize 1\n",
            "2022-05-12 12:01:45,003 : - EPOCH 3 - PROGRESS: at 58.61% examples, 137769 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:01:46,047 : - EPOCH 3 - PROGRESS: at 88.61% examples, 140034 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:46,339 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:46,350 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:46,404 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:46,406 : - EPOCH - 3 : training on 597929 raw words (502788 effective words) took 3.5s, 142060 effective words/s\n",
            "2022-05-12 12:01:47,470 : - EPOCH 4 - PROGRESS: at 26.80% examples, 128103 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:48,539 : - EPOCH 4 - PROGRESS: at 56.93% examples, 134845 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:49,544 : - EPOCH 4 - PROGRESS: at 86.96% examples, 139798 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:49,900 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:49,989 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:50,008 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:50,009 : - EPOCH - 4 : training on 597929 raw words (502779 effective words) took 3.6s, 140016 effective words/s\n",
            "2022-05-12 12:01:51,073 : - EPOCH 5 - PROGRESS: at 26.80% examples, 128303 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:52,101 : - EPOCH 5 - PROGRESS: at 55.26% examples, 133601 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:53,160 : - EPOCH 5 - PROGRESS: at 85.28% examples, 136719 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:53,490 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:53,555 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:53,562 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:53,564 : - EPOCH - 5 : training on 597929 raw words (502746 effective words) took 3.5s, 142014 effective words/s\n",
            "2022-05-12 12:01:54,632 : - EPOCH 6 - PROGRESS: at 26.80% examples, 127750 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:55,709 : - EPOCH 6 - PROGRESS: at 58.61% examples, 138077 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:56,728 : - EPOCH 6 - PROGRESS: at 86.96% examples, 138805 words/s, in_qsize 5, out_qsize 2\n",
            "2022-05-12 12:01:57,042 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:01:57,079 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:01:57,104 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:01:57,105 : - EPOCH - 6 : training on 597929 raw words (502959 effective words) took 3.5s, 142571 effective words/s\n",
            "2022-05-12 12:01:58,126 : - EPOCH 7 - PROGRESS: at 26.80% examples, 133773 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:01:59,162 : - EPOCH 7 - PROGRESS: at 43.56% examples, 107067 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:00,196 : - EPOCH 7 - PROGRESS: at 71.91% examples, 117526 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:02:01,066 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:01,082 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:01,100 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:01,101 : - EPOCH - 7 : training on 597929 raw words (503088 effective words) took 4.0s, 126325 effective words/s\n",
            "2022-05-12 12:02:02,132 : - EPOCH 8 - PROGRESS: at 26.80% examples, 134456 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:03,221 : - EPOCH 8 - PROGRESS: at 58.57% examples, 140708 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:04,306 : - EPOCH 8 - PROGRESS: at 88.61% examples, 140267 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:04,588 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:04,602 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:04,618 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:04,619 : - EPOCH - 8 : training on 597929 raw words (502757 effective words) took 3.5s, 144131 effective words/s\n",
            "2022-05-12 12:02:05,729 : - EPOCH 9 - PROGRESS: at 28.48% examples, 130150 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:02:06,802 : - EPOCH 9 - PROGRESS: at 56.93% examples, 131659 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:07,840 : - EPOCH 9 - PROGRESS: at 85.30% examples, 133599 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:08,234 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:08,275 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:08,282 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:08,286 : - EPOCH - 9 : training on 597929 raw words (502728 effective words) took 3.7s, 137579 effective words/s\n",
            "2022-05-12 12:02:09,300 : - EPOCH 10 - PROGRESS: at 25.12% examples, 126209 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:10,334 : - EPOCH 10 - PROGRESS: at 55.26% examples, 136510 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:11,368 : - EPOCH 10 - PROGRESS: at 83.62% examples, 137069 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:11,831 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:11,836 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:11,851 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:11,853 : - EPOCH - 10 : training on 597929 raw words (503193 effective words) took 3.6s, 141615 effective words/s\n",
            "2022-05-12 12:02:12,942 : - EPOCH 11 - PROGRESS: at 26.80% examples, 124957 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:02:13,999 : - EPOCH 11 - PROGRESS: at 58.61% examples, 137804 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:15,033 : - EPOCH 11 - PROGRESS: at 88.62% examples, 140574 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:15,277 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:15,316 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:15,350 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:15,352 : - EPOCH - 11 : training on 597929 raw words (502784 effective words) took 3.5s, 144161 effective words/s\n",
            "2022-05-12 12:02:16,430 : - EPOCH 12 - PROGRESS: at 28.48% examples, 136141 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:17,512 : - EPOCH 12 - PROGRESS: at 58.61% examples, 138011 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:18,535 : - EPOCH 12 - PROGRESS: at 88.61% examples, 141252 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:18,812 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:18,861 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:18,885 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:18,887 : - EPOCH - 12 : training on 597929 raw words (503109 effective words) took 3.5s, 143406 effective words/s\n",
            "2022-05-12 12:02:19,919 : - EPOCH 13 - PROGRESS: at 26.80% examples, 132577 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:20,922 : - EPOCH 13 - PROGRESS: at 55.26% examples, 137433 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:21,960 : - EPOCH 13 - PROGRESS: at 85.30% examples, 140315 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:22,364 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:22,386 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:22,390 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:22,391 : - EPOCH - 13 : training on 597929 raw words (502999 effective words) took 3.5s, 144184 effective words/s\n",
            "2022-05-12 12:02:23,460 : - EPOCH 14 - PROGRESS: at 28.48% examples, 135787 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:24,470 : - EPOCH 14 - PROGRESS: at 56.93% examples, 138552 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:25,494 : - EPOCH 14 - PROGRESS: at 86.95% examples, 141619 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:25,866 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:25,880 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:25,899 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:25,900 : - EPOCH - 14 : training on 597929 raw words (502807 effective words) took 3.5s, 143946 effective words/s\n",
            "2022-05-12 12:02:26,969 : - EPOCH 15 - PROGRESS: at 26.80% examples, 127948 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:28,012 : - EPOCH 15 - PROGRESS: at 58.61% examples, 140453 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:29,058 : - EPOCH 15 - PROGRESS: at 88.61% examples, 141805 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:29,338 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:29,381 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:29,390 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:29,392 : - EPOCH - 15 : training on 597929 raw words (502902 effective words) took 3.5s, 144641 effective words/s\n",
            "2022-05-12 12:02:30,425 : - EPOCH 16 - PROGRESS: at 26.80% examples, 132284 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:31,473 : - EPOCH 16 - PROGRESS: at 56.95% examples, 138422 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:32,562 : - EPOCH 16 - PROGRESS: at 88.62% examples, 141245 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:32,852 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:32,870 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:32,882 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:32,883 : - EPOCH - 16 : training on 597929 raw words (502927 effective words) took 3.5s, 144676 effective words/s\n",
            "2022-05-12 12:02:33,907 : - EPOCH 17 - PROGRESS: at 26.80% examples, 133452 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:34,915 : - EPOCH 17 - PROGRESS: at 55.26% examples, 137557 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:35,958 : - EPOCH 17 - PROGRESS: at 85.28% examples, 140125 words/s, in_qsize 5, out_qsize 1\n",
            "2022-05-12 12:02:36,334 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:36,348 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:36,370 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:36,371 : - EPOCH - 17 : training on 597929 raw words (502692 effective words) took 3.5s, 144781 effective words/s\n",
            "2022-05-12 12:02:37,453 : - EPOCH 18 - PROGRESS: at 28.48% examples, 133754 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:38,473 : - EPOCH 18 - PROGRESS: at 56.93% examples, 136804 words/s, in_qsize 6, out_qsize 1\n",
            "2022-05-12 12:02:39,498 : - EPOCH 18 - PROGRESS: at 88.61% examples, 143066 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:39,765 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:39,842 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:39,858 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:39,859 : - EPOCH - 18 : training on 597929 raw words (502983 effective words) took 3.5s, 144690 effective words/s\n",
            "2022-05-12 12:02:40,925 : - EPOCH 19 - PROGRESS: at 26.80% examples, 127987 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:41,959 : - EPOCH 19 - PROGRESS: at 55.26% examples, 133033 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:43,058 : - EPOCH 19 - PROGRESS: at 86.96% examples, 137243 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:43,334 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:43,404 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:43,412 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:43,418 : - EPOCH - 19 : training on 597929 raw words (502918 effective words) took 3.5s, 141836 effective words/s\n",
            "2022-05-12 12:02:44,510 : - EPOCH 20 - PROGRESS: at 28.48% examples, 132211 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:45,532 : - EPOCH 20 - PROGRESS: at 58.60% examples, 139930 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:46,569 : - EPOCH 20 - PROGRESS: at 88.61% examples, 141874 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:02:46,851 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:46,866 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:46,898 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:46,900 : - EPOCH - 20 : training on 597929 raw words (502794 effective words) took 3.5s, 144824 effective words/s\n",
            "2022-05-12 12:02:48,042 : - EPOCH 21 - PROGRESS: at 30.14% examples, 134049 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:49,108 : - EPOCH 21 - PROGRESS: at 61.95% examples, 141719 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:50,171 : - EPOCH 21 - PROGRESS: at 93.63% examples, 144479 words/s, in_qsize 4, out_qsize 0\n",
            "2022-05-12 12:02:50,271 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:50,317 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:50,322 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:50,327 : - EPOCH - 21 : training on 597929 raw words (502840 effective words) took 3.4s, 147293 effective words/s\n",
            "2022-05-12 12:02:51,365 : - EPOCH 22 - PROGRESS: at 26.80% examples, 131055 words/s, in_qsize 3, out_qsize 2\n",
            "2022-05-12 12:02:52,441 : - EPOCH 22 - PROGRESS: at 58.61% examples, 139892 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:02:53,457 : - EPOCH 22 - PROGRESS: at 88.61% examples, 142762 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:53,715 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:53,768 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:53,784 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:53,785 : - EPOCH - 22 : training on 597929 raw words (502857 effective words) took 3.4s, 145819 effective words/s\n",
            "2022-05-12 12:02:54,816 : - EPOCH 23 - PROGRESS: at 26.80% examples, 132285 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:02:55,835 : - EPOCH 23 - PROGRESS: at 58.61% examples, 144420 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:56,853 : - EPOCH 23 - PROGRESS: at 86.96% examples, 143085 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:57,167 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:02:57,206 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:02:57,219 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:02:57,220 : - EPOCH - 23 : training on 597929 raw words (502638 effective words) took 3.4s, 146906 effective words/s\n",
            "2022-05-12 12:02:58,335 : - EPOCH 24 - PROGRESS: at 30.15% examples, 137696 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:02:59,376 : - EPOCH 24 - PROGRESS: at 60.28% examples, 141442 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:03:00,436 : - EPOCH 24 - PROGRESS: at 91.97% examples, 144466 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:00,580 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:00,631 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:00,637 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:00,638 : - EPOCH - 24 : training on 597929 raw words (503055 effective words) took 3.4s, 147819 effective words/s\n",
            "2022-05-12 12:03:01,688 : - EPOCH 25 - PROGRESS: at 28.48% examples, 138082 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:02,739 : - EPOCH 25 - PROGRESS: at 58.61% examples, 141063 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:03,784 : - EPOCH 25 - PROGRESS: at 90.27% examples, 145001 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:03,988 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:04,050 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:04,071 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:04,075 : - EPOCH - 25 : training on 597929 raw words (502922 effective words) took 3.4s, 146970 effective words/s\n",
            "2022-05-12 12:03:05,189 : - EPOCH 26 - PROGRESS: at 30.15% examples, 138865 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:06,247 : - EPOCH 26 - PROGRESS: at 61.92% examples, 144335 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:07,250 : - EPOCH 26 - PROGRESS: at 91.94% examples, 146398 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:07,421 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:07,440 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:07,442 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:07,444 : - EPOCH - 26 : training on 597929 raw words (503059 effective words) took 3.4s, 149997 effective words/s\n",
            "2022-05-12 12:03:08,513 : - EPOCH 27 - PROGRESS: at 28.48% examples, 135558 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:09,531 : - EPOCH 27 - PROGRESS: at 48.58% examples, 117661 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:10,598 : - EPOCH 27 - PROGRESS: at 71.91% examples, 115142 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:11,641 : - EPOCH 27 - PROGRESS: at 91.94% examples, 110585 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:11,876 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:11,991 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:11,996 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:12,000 : - EPOCH - 27 : training on 597929 raw words (503041 effective words) took 4.5s, 110759 effective words/s\n",
            "2022-05-12 12:03:13,095 : - EPOCH 28 - PROGRESS: at 15.10% examples, 70738 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:14,106 : - EPOCH 28 - PROGRESS: at 30.15% examples, 72652 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:15,153 : - EPOCH 28 - PROGRESS: at 45.24% examples, 72534 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:03:16,206 : - EPOCH 28 - PROGRESS: at 60.28% examples, 72364 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:17,344 : - EPOCH 28 - PROGRESS: at 78.61% examples, 74249 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:18,162 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:18,223 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:18,244 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:18,246 : - EPOCH - 28 : training on 597929 raw words (502807 effective words) took 6.2s, 80800 effective words/s\n",
            "2022-05-12 12:03:19,350 : - EPOCH 29 - PROGRESS: at 16.78% examples, 77250 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:03:20,374 : - EPOCH 29 - PROGRESS: at 33.48% examples, 79558 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-12 12:03:21,389 : - EPOCH 29 - PROGRESS: at 61.92% examples, 99436 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:22,474 : - EPOCH 29 - PROGRESS: at 93.62% examples, 111743 words/s, in_qsize 3, out_qsize 1\n",
            "2022-05-12 12:03:22,585 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:22,590 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:22,612 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:22,613 : - EPOCH - 29 : training on 597929 raw words (503081 effective words) took 4.4s, 115575 effective words/s\n",
            "2022-05-12 12:03:23,634 : - EPOCH 30 - PROGRESS: at 28.48% examples, 142384 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:24,700 : - EPOCH 30 - PROGRESS: at 56.93% examples, 138121 words/s, in_qsize 5, out_qsize 0\n",
            "2022-05-12 12:03:25,801 : - EPOCH 30 - PROGRESS: at 88.62% examples, 140511 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-12 12:03:26,043 : - worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-12 12:03:26,076 : - worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-12 12:03:26,095 : - worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-12 12:03:26,099 : - EPOCH - 30 : training on 597929 raw words (502851 effective words) took 3.5s, 144969 effective words/s\n",
            "2022-05-12 12:03:26,109 : - training on a 17937870 raw words (15086933 effective words) took 111.2s, 135705 effective words/s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15086933, 17937870)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"google\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsKTP7zyIe2o",
        "outputId": "7fec90b9-a4f4-44b4-c1e2-ed38fa79bebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-12 12:04:10,703 : - precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('reguladores', 0.43487855792045593),\n",
              " ('waze', 0.424803227186203),\n",
              " ('yahoo', 0.3967300355434418),\n",
              " ('android', 0.3943891227245331),\n",
              " ('apple', 0.39112749695777893),\n",
              " ('patentes', 0.37960922718048096),\n",
              " ('concorda', 0.3726450800895691),\n",
              " ('facebook', 0.3719591200351715),\n",
              " ('buffett', 0.3700791895389557),\n",
              " ('verizon', 0.36772656440734863)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"google\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgiBv40fInCb",
        "outputId": "bb7cef44-3232-4e2f-a30f-93d81ec0d18c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', 0.5999081134796143),\n",
              " ('facebook', 0.5410079956054688),\n",
              " ('amazon', 0.5001060962677002),\n",
              " ('waze', 0.4755364656448364),\n",
              " ('fbi', 0.47435659170150757),\n",
              " ('uber', 0.47419095039367676),\n",
              " ('airbnb', 0.4717792868614197),\n",
              " ('web', 0.4630432724952698),\n",
              " ('buffett', 0.44291895627975464),\n",
              " ('canais', 0.43591761589050293)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"gm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvhSd7yTIpO2",
        "outputId": "ec6b2e3f-7200-4bce-fe18-86d71c84a9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('metalúrgicos', 0.5848363637924194),\n",
              " ('honda', 0.5092787742614746),\n",
              " ('motors', 0.5050153732299805),\n",
              " ('airbags', 0.49535268545150757),\n",
              " ('bmw', 0.47285881638526917),\n",
              " ('audi', 0.4693719148635864),\n",
              " ('cubatão', 0.46607792377471924),\n",
              " ('airbag', 0.46572691202163696),\n",
              " ('montadora', 0.4585378170013428),\n",
              " ('patente', 0.45767301321029663)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.most_similar(\"gm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j2WyQ-PIrK7",
        "outputId": "58034f51-2ff4-4be6-80f3-23605663bedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chrysler', 0.6866105198860168),\n",
              " ('honda', 0.6504881381988525),\n",
              " ('fiat', 0.6390398144721985),\n",
              " ('toyota', 0.6367384195327759),\n",
              " ('volks', 0.6337071657180786),\n",
              " ('embraer', 0.6161869764328003),\n",
              " ('renault', 0.6044415235519409),\n",
              " ('tesla', 0.5988296270370483),\n",
              " ('sabmiller', 0.5901549458503723),\n",
              " ('inbev', 0.5830637812614441)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_modelo.wv.save_word2vec_format(path+\"modelo_cbow.txt\", binary=False)\n",
        "w2v_modelo_sg.wv.save_word2vec_format(path+\"modelo_skipgram.txt\", binary=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnC1GaWfIeJv",
        "outputId": "e6d40148-2e1c-4f9b-c6c6-d8c4c403c8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-12 12:04:20,343 : - storing 13006x300 projection weights into /gdrive/MyDrive/NLP_ESTUDOS/Dados/word2vec/modelo_cbow.txt\n",
            "2022-05-12 12:04:23,109 : - storing 13006x300 projection weights into /gdrive/MyDrive/NLP_ESTUDOS/Dados/word2vec/modelo_skipgram.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Word2Vec: treinamento de Word Embedding.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ImOMgSxaLzrEmP6KxkPb9BG0Crgw8PqX",
      "authorship_tag": "ABX9TyMFAdT4XHeiMJYw00ijptWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}